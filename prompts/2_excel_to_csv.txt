PROMPT — STREAMLIT (PÁGINA 1)
EXCEL → CSV BRUTO (ARMAZENAR EM st.session_state) + RESUMO POR ABA + CONSOLIDAÇÃO + MODO TESTE (data/excel)
INCLUIR FUNÇÃO ETL DE NORMALIZAÇÃO DE TEXTO (OPCIONAL) PARA GERAR UM CSV “NORMALIZADO” EM PARALELO

Você é um desenvolvedor Python especialista em Streamlit. Implemente a Página 1 (“Excel → CSV”) de um app.
O objetivo central desta página é transformar planilhas Excel em um único CSV bruto consolidado (arquivo básico de manipulação), armazenar tudo em `st.session_state`, e liberar download.
Além do CSV bruto, a página deve oferecer uma etapa opcional de ETL de normalização textual (minúsculo, limpeza leve e remoção de preposições/artigos) para gerar um segundo CSV “normalizado” em paralelo (sem substituir o bruto).

1. PRINCÍPIO OPERACIONAL (OBRIGATÓRIO)

1) A saída principal desta página é CSV, não Excel.
2) O CSV consolidado bruto é o “formato padrão” de memória e tráfego interno do sistema.
3) O que for carregado e convertido aqui deve ficar disponível para as páginas seguintes via `st.session_state`.

2. ENTRADAS (OBRIGATÓRIO)

A página deve ter dois modos de entrada:

2.1) Modo Upload

1. `st.file_uploader` aceitando `.xlsx` e `.xls` (opcional `.xlsm`).
2. Ao selecionar arquivo, carregar `excel_bytes` e `excel_name`.

2.2) Modo Teste (data/excel)

1. Listar automaticamente arquivos em `data/excel/` com extensões `.xlsx`, `.xls` (opcional `.xlsm`).
2. Permitir:

   1. selecionar 1 arquivo e processar
   2. rodar teste em lote (processar todos) e mostrar um painel por arquivo

3) SAÍDAS (OBRIGATÓRIO)

Para cada arquivo processado, gerar:

3.1) CSV BRUTO CONSOLIDADO

1. `df_all` = concat das abas `ok` com coluna obrigatória `aba`
2. `csv_all_bytes` = bytes do CSV consolidado bruto
3. Nome de download: `<nome_arquivo>__consolidado_bruto.csv`

3.2) CSV NORMALIZADO (OPCIONAL, MAS IMPLEMENTAR)
Se o usuário ativar “Gerar CSV normalizado”, criar:

1. `df_norm` (cópia de `df_all` com normalização textual aplicada apenas em colunas de texto)
2. `csv_norm_bytes`
3. Nome de download: `<nome_arquivo>__consolidado_normalizado.csv`

Importante:

* O CSV normalizado NÃO substitui o bruto. Os dois devem coexistir.
* A normalização aqui é leve e mecânica (ETL de texto), não semântica.

4. VARREDURA POR ABA (OBRIGATÓRIO)

Ao processar o Excel:

1. Descobrir todas as abas do arquivo.
2. Para cada aba:

   1. tentar ler bruto (sem cabeçalho: `header=None` quando aplicável)
   2. medir: `linhas`, `colunas`
   3. definir `status`:

      * `ok` se linhas>0 e colunas>0
      * `empty` se não há conteúdo útil
      * `error` se falhar leitura
   4. registrar `read_method` efetivo e `error_msg` (se houver)

5) EXIBIÇÃO POR ABA (OBRIGATÓRIO)

Para cada aba, criar um `st.expander` exibindo:

1. Nome da aba, linhas, colunas, status, read_method
2. Se status=ok:

   1. preview bruto `head(N)` (N padrão 20, configurável)
3. Se status=empty:

   1. texto “Aba vazia”
4. Se status=error:

   1. texto “Erro ao ler esta aba”
   2. opcional: `error_msg` truncado (ex.: 300–500 caracteres)

6) TABELA RESUMO FINAL POR ABAS (OBRIGATÓRIA E SIMPLES)

Após processar todas as abas, antes do download, exibir uma tabela (DataFrame) com exatamente estas colunas nesta ordem:

1. aba
2. linhas
3. colunas

Regras:

1. A tabela inclui TODAS as abas detectadas, inclusive vazias e com erro.
2. Se `error`, então linhas=0 e colunas=0 (o status fica registrado internamente em `sheets_info`).
3. O nome da aba deve estar na coluna `aba` (não em índice).

Logo abaixo da tabela, exibir texto simples:

1. Total de linhas no CSV consolidado bruto: <N_total>
2. Total de colunas no CSV consolidado bruto: <M_total> (opcional)
3. Contagem de abas: ok = X, empty = Y, error = Z

Se o CSV normalizado estiver habilitado, exibir adicionalmente:

4. Total de linhas no CSV normalizado: <N_total_norm> (deve bater com bruto)
5. Total de colunas no CSV normalizado: <M_total_norm>
6. Observação: “Normalizado altera apenas texto; números permanecem iguais.”

7) CONSOLIDAÇÃO (OBRIGATÓRIO)

1. `df_all` deve ser a concatenação de todas as abas `ok`.
2. Para cada aba `ok`, inserir coluna obrigatória `aba` com o nome da aba.
3. Permitir schemas diferentes entre abas (concat com união de colunas).
4. Não tratar cabeçalho, não renomear colunas, não limpar valores nesta fase.
5. Converter para CSV:

   1. `df_all.to_csv(index=False)`
   2. salvar em bytes (utf-8) para:

      * download
      * persistência no `st.session_state`

8) FUNÇÃO ETL DE NORMALIZAÇÃO TEXTUAL (OPCIONAL, MAS IMPLEMENTAR)

A Página 1 deve incluir uma função separada e testável para normalização textual, aplicada ao `df_all` para gerar `df_norm`.

8.1) Objetivo
Padronizar texto para facilitar reconhecimento posterior:

1. tudo minúsculo
2. remover acentos (configurável, default ligado)
3. remover pontuação e caracteres “ruído”
4. colapsar espaços múltiplos
5. remover preposições/artigos comuns do português (apenas em texto, não em códigos)
6. manter números e medidas (ex.: “25 mm”, “40mpa”, “1/2”) sem destruir

8.2) Regras de aplicação

1. Aplicar apenas em colunas detectadas como texto (object/string).
2. Não aplicar em colunas que pareçam ID/código:

   * nome da coluna contendo: `id`, `codigo`, `código`, `cod`, `cpf`, `cnpj`, `ncm`, `gtin`, `sku`, `chave`
3. A coluna `aba` pode ser normalizada apenas com lower/strip (sem remover tokens).
4. A normalização não deve excluir linhas nem alterar estrutura (mesmas linhas/colunas do df_all).

8.3) Stopwords mínimas (preposições/artigos)
Implementar uma lista mínima e explícita (editável) contendo, por exemplo:

* artigos: `o, a, os, as, um, uma, uns, umas`
* preposições: `de, da, do, das, dos, em, no, na, nos, nas, para, por, com, sem, ao, à, aos, às`
* conectivos comuns: `e`

Regra: remover apenas quando forem tokens isolados (separados por espaço). Não remover dentro de palavras.

8.4) Entregável do ETL

1. Função `normalize_text_value(text: str) -> str`
2. Função `etl_normalize_df(df: pd.DataFrame, config: dict) -> (df_norm, etl_log)`

8.5) Log do ETL (obrigatório se gerar normalizado)
Gerar um log simples com:

1. colunas normalizadas
2. quantidade estimada de células alteradas por coluna
3. exemplos antes/depois (amostra 5–10)

Mostrar isso em um `st.expander` “Log de normalização”.

9. UI DO NORMALIZADO (OBRIGATÓRIO)

Adicionar um bloco “Gerar CSV normalizado” com:

1. checkbox “Gerar também CSV normalizado” (default desligado)
2. toggles:

   1. Remover acentos (default ligado)
   2. Remover pontuação (default ligado)
   3. Remover preposições/artigos (default ligado)
   4. Colapsar espaços (default ligado)
3. preview do `df_norm.head(20)` se habilitado
4. botão de download do normalizado

10) SESSION_STATE (OBRIGATÓRIO)

Persistir no `st.session_state` (para o arquivo atual processado):

1. excel_bytes
2. excel_name
3. excel_source (“upload” | “test_file”)
4. sheets_info (dict por aba: rows, cols, status, read_method, error_msg opcional)
5. df_resumo_abas (tabela de 3 colunas)
6. df_all
7. csv_all_bytes

Se normalizado estiver habilitado:

8. df_norm
9. csv_norm_bytes
10. etl_log_norm (log da normalização + configurações)

Para modo lote (teste em lote):

11. batch_test_results_df (por arquivo: abas_total, ok, empty, error, linhas_csv, colunas_csv)
12. batch_test_details (por arquivo: sheets_info, df_resumo_abas, csv_all_bytes, opcional csv_norm_bytes)

11) ORGANIZAÇÃO DO CÓDIGO (OBRIGATÓRIO)

Implementar funções puras (reutilizáveis para upload e teste):

1. list_test_files("data/excel")
2. load_excel_bytes(source) -> (excel_bytes, excel_name)
3. list_sheets(excel_bytes, ext)
4. read_sheet(excel_bytes, ext, sheet_name) -> df + read_method
5. process_workbook(excel_bytes, excel_name) -> sheets_info + df_resumo_abas + df_all + csv_all_bytes
6. normalize_text_value(text, config)
7. etl_normalize_df(df_all, config) -> df_norm + etl_log
8. run_batch_test(paths) -> batch_results_df + batch_details

12) CRITÉRIOS DE SUCESSO

1. Excel sempre vira CSV bruto consolidado e baixável.
2. O CSV bruto e seus bytes ficam em `st.session_state`.
3. O resumo por abas sempre aparece com 3 colunas exatas.
4. Modo teste lê arquivos em `data/excel/` e funciona igual ao upload.
5. Se normalizado estiver habilitado, gera segundo CSV e log, sem alterar o bruto.
