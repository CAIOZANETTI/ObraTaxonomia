import streamlit as st
import pandas as pd
import io
import os
import time
import sys

# Adicionar root ao path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from scripts.builder import TaxonomyBuilder
from scripts.classify import ClassifierEngine
from scripts.unknowns import aggregate_unknowns

st.set_page_config(page_title="4. Apelidar e Validar", layout="wide")

# --- Inicializa√ß√£o da Engine (Cache) ---
@st.cache_resource
def get_engine():
    # Caminho relativo para yaml
    base_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'yaml')
    builder = TaxonomyBuilder(base_dir).load_all()
    classifier = ClassifierEngine(builder)
    return classifier

    return classifier

if st.button("üîÑ Recarregar Regras (Limpar Cache)"):
    st.cache_resource.clear()
    
    # For√ßar reclassifica√ß√£o dos dados
    if 'df_working' in st.session_state:
        del st.session_state['df_working']
        
    st.success("Cache e Dados limpos! O classificador rodar√° novamente.")
    st.rerun()

classifier = get_engine()

st.header("4. Classifica√ß√£o e Valida√ß√£o")
st.markdown("O sistema sugere apelidos baseados na taxonomia. Voc√™ valida ou corrige.")

# --- Verifica√ß√µes de Sess√£o ---
if 'csv_norm' not in st.session_state:
    st.error("Dados normalizados n√£o encontrados. Volte para a p√°gina 3.")
    if st.button("Voltar"):
        st.switch_page("pages/3_Normalizar.py")
    st.stop()

# --- Carregar Dados ---
if 'df_working' not in st.session_state:
    try:
        df_norm = pd.read_csv(io.StringIO(st.session_state['csv_norm']))
        
        # Adicionar ID original para preservar ordem da planilha
        if 'id_original' not in df_norm.columns:
            df_norm.insert(0, 'id_original', range(1, len(df_norm) + 1))
        
        # Inicializar colunas de trabalho se n√£o existirem
        if 'apelido_sugerido' not in df_norm.columns:
            # Ainda n√£o rodou classificador
            # Vamos rodar automaticamente na primeira vez
            with st.spinner("Classificando pela primeira vez..."):
                result_df = classifier.process_dataframe(df_norm, col_desc='descricao_norm', col_unit='unidade')
                # Merge
                # O process_dataframe retorna um df com mesmo index, ent√£o concat axis=1 funciona se index alinhado
                # Mas para garantir, vamos fazer concat e remover duplicatas se tiver
                df_combined = pd.concat([df_norm, result_df], axis=1)
                
                # Inicializar coluna de revis√£o
                df_combined['revisar'] = False
                
                # Inicializar coluna de apelido desejado (feedback do usu√°rio)
                if 'apelido_desejado' not in df_combined.columns:
                    df_combined['apelido_desejado'] = ''
                
            st.session_state['df_working'] = df_combined
        else:
            st.session_state['df_working'] = df_norm
            
    except Exception as e:
        st.error(f"Erro ao preparar dados: {e}")
        st.stop()
else:
    # Recarregar do session state (pode ter edi√ß√µes anteriores)
    df_combined = st.session_state['df_working']

# --- Migra√ß√£o de Dados Antigos ---
# Se existe coluna 'validado' mas n√£o existe 'revisar', migrar
if 'validado' in df_combined.columns and 'revisar' not in df_combined.columns:
    # Migrar: inverter l√≥gica (validado=True vira revisar=False)
    df_combined['revisar'] = False
    st.session_state['df_working'] = df_combined
    st.info("‚ö†Ô∏è Dados migrados para novo formato. A coluna 'Validado' foi substitu√≠da por 'Revisar'.")

# Se n√£o existe coluna 'revisar', criar
if 'revisar' not in df_combined.columns:
    df_combined['revisar'] = False
    st.session_state['df_working'] = df_combined

# Se n√£o existe coluna 'apelido_desejado', criar
if 'apelido_desejado' not in df_combined.columns:
    df_combined['apelido_desejado'] = ''
    st.session_state['df_working'] = df_combined

# --- M√©tricas ---
df = df_combined # Alias curto

total = len(df)
marcados_revisar = df['revisar'].sum()
ok = len(df[df['query_status']=='ok']) if 'query_status' in df.columns else len(df[df['status'] == 'ok']) # fallback compatibility
status_revisar = len(df[df['status'] == 'revisar'])
desconhecidos = len(df[df['status'] == 'desconhecido'])

m1, m2, m3, m4 = st.columns(4)
m1.metric("Total de Itens", total)
m2.metric("Sugest√£o Certa (OK)", ok)
m3.metric("Status: Revisar", status_revisar)
m4.metric("Desconhecidos", desconhecidos)
st.metric("Marcados para Revis√£o", f"{marcados_revisar} itens")

# --- Filtros e Controles ---
st.divider()

with st.expander("üîç Filtros Avan√ßados", expanded=True):
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Filtro por Status
        status_filter = st.multiselect(
            "Status",
            options=['ok', 'revisar', 'desconhecido'],
            default=['ok', 'revisar', 'desconhecido']
        )
    
    with col2:
        # Filtro por Revisar
        revisar_filter = st.multiselect(
            "Revisar",
            options=['Marcado', 'N√£o Marcado'],
            default=['Marcado', 'N√£o Marcado']
        )
    
    with col3:
        # Filtro por Tipo (Dom√≠nio)
        tipos_disponiveis = ['Todos'] + sorted(df['tax_tipo'].dropna().unique().tolist())
        tipo_filter = st.selectbox(
            "Tipo (Dom√≠nio)",
            options=tipos_disponiveis,
            index=0
        )
    
    # Segunda linha de filtros
    col4, col5, col6, col7 = st.columns(4)
    
    with col4:
        # Filtro por Grupo (Arquivo YAML) - apenas se coluna existir
        if 'tax_grupo' in df.columns:
            # Filtrar grupos baseado no tipo selecionado
            if tipo_filter != 'Todos':
                grupos_disponiveis = ['Todos'] + sorted(
                    df[df['tax_tipo'] == tipo_filter]['tax_grupo'].dropna().unique().tolist()
                )
            else:
                grupos_disponiveis = ['Todos'] + sorted(df['tax_grupo'].dropna().unique().tolist())
            
            grupo_filter = st.selectbox(
                "Grupo (Arquivo YAML)",
                options=grupos_disponiveis,
                index=0
            )
        else:
            grupo_filter = 'Todos'
            st.info("‚ÑπÔ∏è Coluna 'tax_grupo' n√£o dispon√≠vel. Atualize o classificador.")
    
    with col5:
        # Filtro por Apelido
        # Filtrar apelidos baseado no grupo selecionado
        if 'tax_grupo' in df.columns and grupo_filter != 'Todos':
            apelidos_disponiveis = ['Todos'] + sorted(
                df[df['tax_grupo'] == grupo_filter]['apelido_sugerido'].dropna().unique().tolist()
            )
        elif tipo_filter != 'Todos':
            apelidos_disponiveis = ['Todos'] + sorted(
                df[df['tax_tipo'] == tipo_filter]['apelido_sugerido'].dropna().unique().tolist()
            )
        else:
            apelidos_disponiveis = ['Todos'] + sorted(df['apelido_sugerido'].dropna().unique().tolist())
        
        apelido_filter = st.selectbox(
            "Apelido Sugerido",
            options=apelidos_disponiveis,
            index=0
        )
    
    with col6:
        # Toggle para mostrar semelhantes
        show_similares = st.toggle("Mostrar Semelhantes", value=False)
    
    with col7:
        # Filtro de busca por texto na descri√ß√£o
        search_text = st.text_input("Buscar na descri√ß√£o", placeholder="Digite para filtrar...")

# Filtragem do DataFrame para Exibi√ß√£o
mask = df['status'].isin(status_filter)

# Aplicar filtro de revisar
if 'Marcado' in revisar_filter and 'N√£o Marcado' not in revisar_filter:
    mask = mask & (df['revisar'] == True)
elif 'N√£o Marcado' in revisar_filter and 'Marcado' not in revisar_filter:
    mask = mask & (df['revisar'] == False)
# Se ambos ou nenhum estiver selecionado, n√£o filtra por revisar

# Aplicar filtro de tipo
if tipo_filter != 'Todos':
    mask = mask & (df['tax_tipo'] == tipo_filter)

# Aplicar filtro de grupo (apenas se coluna existir)
if 'tax_grupo' in df.columns and grupo_filter != 'Todos':
    mask = mask & (df['tax_grupo'] == grupo_filter)

# Aplicar filtro de apelido
if apelido_filter != 'Todos':
    mask = mask & (df['apelido_sugerido'] == apelido_filter)

# Aplicar filtro de busca por texto
if search_text:
    mask = mask & df['descricao_norm'].str.contains(search_text.lower(), case=False, na=False)

df_view = df[mask].copy()

# --- Configura√ß√£o de Colunas Dispon√≠veis (Mapeamento Interno -> Label) ---
COL_LABELS = {
    "revisar": "Revisar?",
    "descricao_norm": "Descri√ß√£o (Norm)",
    "unidade": "Und",
    "quantidade": "Qtd",
    "tax_tipo": "Tipo",
    "tax_grupo": "Grupo",
    "apelido_sugerido": "Sugest√£o",
    "apelido_desejado": "Apelido Desejado",
    "status": "Status",
    "motivo": "Motivo",
    "codigo": "C√≥digo",
    "preco_unit": "Pre√ßo Unit.",
    "preco_total": "Pre√ßo Total"
}

# Defaults vis√≠veis
DEFAULT_VISIBLE = ["revisar", "descricao_norm", "tax_tipo", "tax_grupo", "apelido_sugerido", "apelido_desejado", "status"]

with st.expander("üëÅÔ∏è Configurar Colunas Vis√≠veis", expanded=False):
    visible_cols = st.multiselect(
        "Selecione as colunas para exibir:",
        options=list(COL_LABELS.keys()),
        default=DEFAULT_VISIBLE,
        format_func=lambda x: COL_LABELS[x]
    )

# --- Tabela Edit√°vel ---
# Definir configura√ß√£o base das colunas
col_config = {
    "revisar": st.column_config.CheckboxColumn("Revisar?", width="small", help="Marque os itens que precisam revis√£o"),
    "descricao_norm": st.column_config.TextColumn("Descri√ß√£o (Norm)", disabled=True, width="large"),
    "unidade": st.column_config.TextColumn("Und", disabled=True, width="small"),
    "quantidade": st.column_config.NumberColumn("Qtd", disabled=True, format="%.2f"),
    "tax_tipo": st.column_config.TextColumn("Tipo", disabled=True, width="small", help="Diret√≥rio YAML (ex: estrutura, fundacao)"),
    "tax_grupo": st.column_config.TextColumn("Grupo", disabled=True, width="small", help="Arquivo YAML (ex: concreto, aco)"),
    "apelido_sugerido": st.column_config.TextColumn("Sugest√£o", disabled=True),
    "status": st.column_config.TextColumn("Status", disabled=True, width="small"),
    "motivo": st.column_config.TextColumn("Motivo", disabled=True),
    "codigo": st.column_config.TextColumn("C√≥digo", disabled=True, width="small"),
    "preco_unit": st.column_config.NumberColumn("Pre√ßo Unit.", disabled=True, format="%.2f"),
    "preco_total": st.column_config.NumberColumn("Pre√ßo Total", disabled=True, format="%.2f"),
    # Esconder colunas t√©cnicas sempre
    "id_linha": None, "linha_origem": None, "aba_origem": None, 
    "alternativa": None, "score": None, "tax_desconhecido": None,
    "unidade_sugerida": None, "tax_incerto": None, "tax_confianca": None, "tax_apelido": None,
    "apelido_final": None  # Esconder apelido_final
}

# Aplicar filtro de visibilidade
# Para cada coluna que N√ÉO est√° em visible_cols, setar como None (esconder)
for col_key in COL_LABELS.keys():
    if col_key not in visible_cols:
        col_config[col_key] = None

# L√≥gica Din√¢mica para Semelhantes (Toggle soberano)
if show_similares:
    col_config["semelhantes"] = st.column_config.TextColumn("Semelhantes", disabled=True)
else:
    col_config["semelhantes"] = None

st.caption("Marque os itens que precisam revis√£o. Baixe o CSV de itens marcados para aprendizado.")

edited_df_view = st.data_editor(
    df_view,
    column_config=col_config,
    use_container_width=True,
    hide_index=True,
    key="editor_validation" # Key fixa para n√£o resetar em rerun parcial
)

# --- Sincroniza√ß√£o de Edi√ß√µes ---
# O st.data_editor retorna apenas as linhas que estavam vis√≠veis (df_view) com as edi√ß√µes.
# Precisamos atualizar o df principal (st.session_state['df_working']) com essas edi√ß√µes.
# Usamos o index original que foi preservado no df_view.

if st.button("üíæ Salvar Altera√ß√µes na Sess√£o"):
    # Atualizar o DataFrame mestre com as edi√ß√µes do view
    # Pandas update √© eficiente com √≠ndices alinhados
    st.session_state['df_working'].update(edited_df_view)
    
    # Atualizar status baseado na marca√ß√£o de revisar
    # Se marcou revisar=True, mudar status para 'revisar'
    # Se desmarcou revisar=False e status era 'revisar', voltar para status original ou 'ok'
    mask_marcado = st.session_state['df_working']['revisar'] == True
    st.session_state['df_working'].loc[mask_marcado, 'status'] = 'revisar'
    
    # Se desmarcou e status √© 'revisar', voltar para 'ok' (assumindo que estava ok antes)
    mask_desmarcado = st.session_state['df_working']['revisar'] == False
    mask_status_revisar = st.session_state['df_working']['status'] == 'revisar'
    st.session_state['df_working'].loc[mask_desmarcado & mask_status_revisar, 'status'] = 'ok'
    
    st.success("Altera√ß√µes salvas! Status atualizado automaticamente.")
    st.rerun() # Refresh nas m√©tricas

# --- Exporta√ß√£o ---
st.divider()
st.subheader("Finalizar e Exportar")

# Primeira linha de bot√µes
c1, c2, c3, c4 = st.columns(4)

if c1.button("Voltar"):
    st.switch_page("pages/3_Normalizar.py")

# Bot√£o Download Validado (Completo) - Ordenado pela ordem original
df_export = st.session_state['df_working'].copy()
if 'id_original' in df_export.columns:
    df_export = df_export.sort_values('id_original')

csv_validado = df_export.to_csv(index=False).encode('utf-8')
c2.download_button(
    label="üì• Baixar Completo",
    data=csv_validado,
    file_name="orcamento_validado.csv",
    mime="text/csv",
    help="Baixa todos os dados processados na ordem original da planilha."
)

# Bot√£o Download Marcados para Revisar (Aprendizado)
marcados_revisar_df = st.session_state['df_working'][
    st.session_state['df_working']['revisar'] == True
].copy()
if 'id_original' in marcados_revisar_df.columns:
    marcados_revisar_df = marcados_revisar_df.sort_values('id_original')

csv_marcados = marcados_revisar_df.to_csv(index=False).encode('utf-8')
c3.download_button(
    label="üì• Marcados Revisar",
    data=csv_marcados,
    file_name="aprendizado_revisar.csv",
    mime="text/csv",
    help=f"Baixa {len(marcados_revisar_df)} itens marcados para revis√£o ‚Üí data/aprendizado/revisar/"
)

# Bot√£o Download Desconhecidos (Aprendizado)
unknowns_df = st.session_state['df_working'][
    st.session_state['df_working']['tax_desconhecido'] == True
].copy()
if 'id_original' in unknowns_df.columns:
    unknowns_df = unknowns_df.sort_values('id_original')

csv_unknowns = unknowns_df.to_csv(index=False).encode('utf-8')
c4.download_button(
    label="üì• Desconhecidos",
    data=csv_unknowns,
    file_name="aprendizado_desconhecidos.csv",
    mime="text/csv",
    help=f"Baixa {len(unknowns_df)} itens desconhecidos ‚Üí data/aprendizado/desconhecidos/"
)

# Segunda linha - Bot√£o de continuar
st.markdown("")  # Espa√ßamento

# Bot√£o Continuar para Unknowns (Gest√£o)
# Salva unknowns na sess√£o antes de ir
if st.button("Gerir Desconhecidos >", type="primary"):
    # Salvar estado final - ordenado pela ordem original
    df_final = st.session_state['df_working'].copy()
    if 'id_original' in df_final.columns:
        df_final = df_final.sort_values('id_original')
    
    st.session_state['csv_validated'] = df_final.to_csv(index=False)
    
    # Gerar Unknowns
    # Consideramos unknown aquilo que ainda est√° marked as unknown OU n√£o foi validado/preenchido
    # Mas para o report de unknowns puro, usamos tax_desconhecido original da classifica√ß√£o?
    # Ou o residual?
    # Arquitetura diz: "Unknowns n√£o s√£o erro; s√£o fila de melhoria".
    # Ent√£o exportamos o que o sistema N√ÉO conseguiu resolver sozinho ou o usu√°rio confirmou que n√£o existe.
    # Vamos usar a flag tax_desconhecido atualizada
    
    st.switch_page("pages/5_Desconhecidos.py")
